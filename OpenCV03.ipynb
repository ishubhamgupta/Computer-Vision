{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colour Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the image \n",
    "image = cv2.imread('./Downloads/sample1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input file\n",
    "cv2.imshow('Our Original Image', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 149 0\n",
      "(360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# BGR Values for the first 0,0 pixel\n",
    "B, G, R = image[10, 50] \n",
    "print(B, G, R)\n",
    "print(image.shape) # Our original Shape of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 169 55\n",
      "(360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# BGR Values for the first 0,0 pixel\n",
    "B, G, R = image[50, 100] # We are changing pixel sets\n",
    "print(B, G, R)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640)\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "print(gray_img.shape)\n",
    "print(gray_img[10, 50]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640)\n",
      "184\n"
     ]
    }
   ],
   "source": [
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "print(gray_img.shape)\n",
    "print(gray_img[100, 500]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's evidient that now we have only 2 dimensions, where each pixel coordinate has only one value (previously it was 3) with a range of 0 to 255 (it can't go beyond 256). With the change in pixel demands the cooresponding GrayScale changes and this happens because of the intensity / nature of the feeded image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img[2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we can observ that at different coordinate points the intensity of image is changing continuously and this is happening because we are now playing with just two colours Black and White and as the intensity changes this shows there proportion aur activeness to drive out meaningful image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSV Colour space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H** - Hue (0 - 180)  \n",
    "\n",
    "**S** - Saturation (0 - 255)\n",
    "\n",
    "**V** - Value / Intensity (0 - 255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is one of the very important technique in colour filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intially we are convert our original image to HSV\n",
    "\n",
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the HSV version of our BGR image / original image\n",
    "\n",
    "cv2.imshow('HSV image', hsv_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check only for the Hue portion by rejecting others\n",
    "\n",
    "cv2.imshow('Hue channel', hsv_image[:, :, 0])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check only for the Hue portion by rejecting others\n",
    "\n",
    "cv2.imshow('Saturation channel', hsv_image[:, :, 1])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check only for the Hue portion by rejecting others\n",
    "\n",
    "cv2.imshow('Value channel', hsv_image[:, :, 2])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R, G, B are all co-related to the colour luminance i.e. we cannot separate colour information from luminance.\n",
    "HSV is used to separate image luminance from colour information.\n",
    "This makes it easier when we are working on or we need luminance of the image / frame.\n",
    "HSV also used in situations where colour descriptions palys an integral role.\n",
    "Inshort HSV images helps us to focus on the required element which is essential for our operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual channel of an RGB image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenCV's 'SPLIT' function splites the image into each color index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B component (360, 640)\n",
      "G component (360, 640)\n",
      "R component (360, 640)\n"
     ]
    }
   ],
   "source": [
    "B, G, R = cv2.split(image)\n",
    "\n",
    "print('B component',B.shape)\n",
    "print('G component',G.shape)\n",
    "print('R component',R.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can observ the pixel remains throughout the same for a particular image. We are mainly focusing on getting the individual component related to that image and see its effect in the absence of the other two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see individually when only Red element is present and rest two are absent \n",
    "\n",
    "cv2.imshow(\"Our Image with just Red component\", R)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see individually when only Green element is present and rest two are absent \n",
    "\n",
    "cv2.imshow(\"Our Image with just Green component\", G)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see individually when only Blue element is present and rest two are absent \n",
    "\n",
    "cv2.imshow(\"Our Image with just Blue component\", B)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recreating our original image from B, G, R by using OpenCV's MERGE function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = cv2.merge([B, G, R]) \n",
    "cv2.imshow(\"Our Merged Image\", merged) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can even amplify our images by playing around B, G, R component**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = cv2.merge([B+100, G, R])\n",
    "cv2.imshow(\"Our Merged image with Blue Amplified\", merged) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = cv2.merge([B, G+100, R])\n",
    "cv2.imshow(\"Our Merged image with Green Amplified\", merged) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = cv2.merge([B, G, R+100])\n",
    "cv2.imshow(\"Our Merged image with Green Amplified\", merged) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When all are amplified**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = cv2.merge([B+100, G+100, R+100])\n",
    "cv2.imshow(\"Our Merged image with Every Element Amplified\", merged) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now I'm going to create a matrix of zeros, with dimensions of the image H x W** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "# uint8 - Unsigned integer (0 to 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"When Red\", cv2.merge([zeros, zeros, R]))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"When Green\", cv2.merge([zeros, G, zeros]))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"When Blue\", cv2.merge([B, zeros, zeros]))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python OCV4",
   "language": "python",
   "name": "ocv4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
